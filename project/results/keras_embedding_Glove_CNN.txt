"""
First attempt with CNN
Some parameters taken from https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html
Pooling too big for such short titles. Adjust later.
Still, a 7% improvement for score of 0.57
"""
Loaded 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_6 (Embedding)      (None, 26, 100)           7509400   
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 22, 128)           64128     
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 4, 128)            0         
_________________________________________________________________
conv1d_4 (Conv1D)            (None, 2, 128)            49280     
_________________________________________________________________
max_pooling1d_4 (MaxPooling1 (None, 1, 128)            0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 128)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 128)               16512     
_________________________________________________________________
dense_6 (Dense)              (None, 32)                4128      
=================================================================
Total params: 7,643,448
Trainable params: 134,048
Non-trainable params: 7,509,400
_________________________________________________________________
None
Train on 186814 samples, validate on 20758 samples
Epoch 1/15
186814/186814 [==============================] - 53s 285us/step - loss: 1.7734 - acc: 0.5010 - val_loss: 1.6151 - val_acc: 0.5473
Epoch 2/15
186814/186814 [==============================] - 52s 277us/step - loss: 1.5145 - acc: 0.5689 - val_loss: 1.5428 - val_acc: 0.5654
Epoch 3/15
186814/186814 [==============================] - 53s 282us/step - loss: 1.4175 - acc: 0.5933 - val_loss: 1.5334 - val_acc: 0.5669
Epoch 4/15
186814/186814 [==============================] - 51s 272us/step - loss: 1.3541 - acc: 0.6097 - val_loss: 1.5432 - val_acc: 0.5702
Epoch 5/15
186814/186814 [==============================] - 51s 272us/step - loss: 1.3001 - acc: 0.6228 - val_loss: 1.5457 - val_acc: 0.5696
Epoch 6/15
186814/186814 [==============================] - 52s 279us/step - loss: 1.2564 - acc: 0.6328 - val_loss: 1.5655 - val_acc: 0.5727
Epoch 7/15
186814/186814 [==============================] - 51s 275us/step - loss: 1.2196 - acc: 0.6434 - val_loss: 1.5802 - val_acc: 0.5710
Epoch 8/15
186814/186814 [==============================] - 51s 274us/step - loss: 1.1838 - acc: 0.6505 - val_loss: 1.6188 - val_acc: 0.5693
Epoch 9/15
186814/186814 [==============================] - 52s 276us/step - loss: 1.1536 - acc: 0.6588 - val_loss: 1.6093 - val_acc: 0.5697


"""
Simpler model, max-pooled from a single convolutional layer (3 word window)
Slightly better result: 58%
"""
Loaded 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_11 (Embedding)     (None, 26, 100)           7509400   
_________________________________________________________________
conv1d_12 (Conv1D)           (None, 24, 128)           38528     
_________________________________________________________________
max_pooling1d_12 (MaxPooling (None, 1, 128)            0         
_________________________________________________________________
flatten_8 (Flatten)          (None, 128)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 32)                4128      
=================================================================
Total params: 7,552,056
Trainable params: 42,656
Non-trainable params: 7,509,400
_________________________________________________________________
None
Train on 186814 samples, validate on 20758 samples
Epoch 1/5
186814/186814 [==============================] - 40s 215us/step - loss: 1.7241 - acc: 0.5197 - val_loss: 1.5566 - val_acc: 0.5642
Epoch 2/5
186814/186814 [==============================] - 40s 216us/step - loss: 1.5025 - acc: 0.5750 - val_loss: 1.5137 - val_acc: 0.5773
Epoch 3/5
186814/186814 [==============================] - 41s 218us/step - loss: 1.4392 - acc: 0.5918 - val_loss: 1.4938 - val_acc: 0.5803
Epoch 4/5
186814/186814 [==============================] - 40s 217us/step - loss: 1.3991 - acc: 0.6024 - val_loss: 1.4955 - val_acc: 0.5815
Epoch 5/5
186814/186814 [==============================] - 41s 219us/step - loss: 1.3723 - acc: 0.6092 - val_loss: 1.4974 - val_acc: 0.5830
20758/20758 [==============================] - 2s 80us/step
Accuracy: 58.300414


# 5 word and 7 word windows had same result

"""
Same as above (window size 3), but with an extra dense layer
No improvement on validation data
"""
Loaded 400000 word vectors.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_13 (Embedding)     (None, 26, 100)           7509400   
_________________________________________________________________
conv1d_14 (Conv1D)           (None, 24, 128)           38528     
_________________________________________________________________
max_pooling1d_14 (MaxPooling (None, 1, 128)            0         
_________________________________________________________________
flatten_10 (Flatten)         (None, 128)               0         
_________________________________________________________________
dense_15 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_16 (Dense)             (None, 32)                4128      
=================================================================
Total params: 7,568,568
Trainable params: 59,168
Non-trainable params: 7,509,400
_________________________________________________________________
None
Train on 186814 samples, validate on 20758 samples
Epoch 1/5
186814/186814 [==============================] - 46s 249us/step - loss: 1.7097 - acc: 0.5180 - val_loss: 1.5470 - val_acc: 0.5618
Epoch 2/5
186814/186814 [==============================] - 45s 243us/step - loss: 1.4836 - acc: 0.5779 - val_loss: 1.5022 - val_acc: 0.5720
Epoch 3/5
186814/186814 [==============================] - 45s 243us/step - loss: 1.4086 - acc: 0.5972 - val_loss: 1.4670 - val_acc: 0.5845
Epoch 4/5
186814/186814 [==============================] - 46s 245us/step - loss: 1.3602 - acc: 0.6079 - val_loss: 1.4708 - val_acc: 0.5849
Epoch 5/5
186814/186814 [==============================] - 46s 244us/step - loss: 1.3256 - acc: 0.6174 - val_loss: 1.4693 - val_acc: 0.5835
20758/20758 [==============================] - 2s 81us/step
Accuracy: 58.353406


"""
256 features, still a single layer of 3 window followed by maxpool
59%
"""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_15 (Embedding)     (None, 26, 100)           7509400   
_________________________________________________________________
conv1d_16 (Conv1D)           (None, 24, 256)           77056     
_________________________________________________________________
max_pooling1d_16 (MaxPooling (None, 1, 256)            0         
_________________________________________________________________
flatten_12 (Flatten)         (None, 256)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 32)                8224      
=================================================================
Total params: 7,594,680
Trainable params: 85,280
Non-trainable params: 7,509,400
_________________________________________________________________
None
Train on 186814 samples, validate on 20758 samples
Epoch 1/5
186814/186814 [==============================] - 49s 261us/step - loss: 1.6621 - acc: 0.5353 - val_loss: 1.5270 - val_acc: 0.5683
Epoch 2/5
186814/186814 [==============================] - 48s 255us/step - loss: 1.4298 - acc: 0.5937 - val_loss: 1.4693 - val_acc: 0.5895
Epoch 3/5
186814/186814 [==============================] - 48s 257us/step - loss: 1.3428 - acc: 0.6173 - val_loss: 1.4704 - val_acc: 0.5895
Epoch 4/5
186814/186814 [==============================] - 47s 253us/step - loss: 1.2859 - acc: 0.6318 - val_loss: 1.4591 - val_acc: 0.5937
Epoch 5/5
186814/186814 [==============================] - 47s 250us/step - loss: 1.2427 - acc: 0.6425 - val_loss: 1.4815 - val_acc: 0.5930
20758/20758 [==============================] - 2s 81us/step
Accuracy: 59.297620

"""
512 is about the same as 256
"""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_16 (Embedding)     (None, 26, 100)           7509400   
_________________________________________________________________
conv1d_17 (Conv1D)           (None, 24, 512)           154112    
_________________________________________________________________
max_pooling1d_17 (MaxPooling (None, 1, 512)            0         
_________________________________________________________________
flatten_13 (Flatten)         (None, 512)               0         
_________________________________________________________________
dense_19 (Dense)             (None, 32)                16416     
=================================================================
Total params: 7,679,928
Trainable params: 170,528
Non-trainable params: 7,509,400
_________________________________________________________________
None
Train on 186814 samples, validate on 20758 samples
Epoch 1/5
186814/186814 [==============================] - 60s 322us/step - loss: 1.6207 - acc: 0.5450 - val_loss: 1.4756 - val_acc: 0.5862
Epoch 2/5
186814/186814 [==============================] - 60s 319us/step - loss: 1.3755 - acc: 0.6098 - val_loss: 1.4353 - val_acc: 0.5975
Epoch 3/5
186814/186814 [==============================] - 60s 320us/step - loss: 1.2597 - acc: 0.6401 - val_loss: 1.4287 - val_acc: 0.6050
Epoch 4/5
186814/186814 [==============================] - 59s 318us/step - loss: 1.1740 - acc: 0.6623 - val_loss: 1.4716 - val_acc: 0.6003
Epoch 5/5
186814/186814 [==============================] - 60s 322us/step - loss: 1.1059 - acc: 0.6783 - val_loss: 1.4910 - val_acc: 0.5975
20758/20758 [==============================] - 2s 91us/step
Accuracy: 59.745640

